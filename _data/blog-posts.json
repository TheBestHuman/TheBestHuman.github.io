[
  {
    "id": "684b23a89d1d6d0001047191",
    "uuid": "d8f4aa5f-3461-4f05-a79b-890a92934169",
    "title": "I Wrote My Dream App in 4 Hours",
    "slug": "i-wrote-my-dream-app-in-4-hours",
    "html": "<p>Since the release of GPT 3.5 (almost 3 years ago!) I’ve had a few app ideas that I’ve used as a benchmark for how good LLMs are at coding. It’s a list of projects that I test each major model and tool breakthroughs against, and if I can build one of these projects, it represents a true advancement in the field. With GitHub Copilot Agent Mode, I’ve finally been able to build the first app on my list, <a href=\"https://melticulous.com/?ref=pr.ogra.ms\" rel=\"noreferrer\">Melticulous</a>.</p><p>My entire family is obsessed with <a href=\"https://en.wikipedia.org/wiki/Fuse_beads?ref=pr.ogra.ms\" rel=\"noreferrer\">Perler Beads</a> (generic name: fuse beads.) It’s a deceptively simple craft where you arrange small beads on a grid of pegs and then fuse them together with a hot iron. You can create really elaborate designs with them, and they’re really good for making pixel art.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://pr.ogra.ms/content/images/2025/06/IMG_8937.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"868\" srcset=\"https://pr.ogra.ms/content/images/size/w600/2025/06/IMG_8937.png 600w, https://pr.ogra.ms/content/images/size/w1000/2025/06/IMG_8937.png 1000w, https://pr.ogra.ms/content/images/size/w1600/2025/06/IMG_8937.png 1600w, https://pr.ogra.ms/content/images/size/w2400/2025/06/IMG_8937.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">A perler bead pattern of Nintendo's Mario</span></figcaption></figure><p>I‘ve long wanted to create an app that turns arbitrary images into Perler bead patterns. I think it would be really neat to be able to make hangable art based on photos of your kids, or landscapes you took on your dream vacation.</p><h3 id=\"proof-of-concept\">Proof of Concept</h3><p>I’ve been trying to build this app on every LLM model since 2022, with a slow progression of results, but I would always get stuck on the <a href=\"https://en.wikipedia.org/wiki/Color_quantization?ref=pr.ogra.ms\" rel=\"noreferrer\">color quantization</a> algorithm. That is - the algorithm for choosing which colors should be part of the palette. I wanted to limit the number of colors to 16, because who (besides my wife) has a warehouse full of beads? But many images have millions of different colors and I know nothing about the math involved with reducing the number of colors in an image. This is what I needed LLMs for; somehow magically figuring out the math involved in quantizing the colors in a way that felt correct to the user. With every model, I was hitting a brick wall at this stage. </p><p>That is, until VSCode (GitHub Copilot) added agent mode and increased their context windows back in <a href=\"https://code.visualstudio.com/blogs/2025/04/07/agentMode?ref=pr.ogra.ms\" rel=\"noreferrer\">April</a>.  I tried prompting it on a whim using the free mode with GPT-4o and to my surprise, it only took a few tweaks to get a working proof of concept! Here's my experience taking it from PoC to a solid, usable app, with some tips along the way.</p><h3 id=\"how-does-it-work-just-ask\">How does it work? Just ask!</h3><p>I showed a few people the PoC and got some feedback, but the biggest question software developers asked was \"How does it work?\" I knew that the key breakthrough was to ask it to choose the most unalike colors to be part of the palette, but I didn't know <em>how</em> it made that choice. So I just asked!</p><blockquote>generate a document for me that gives me enough information about the app to discuss it with other devs. it should include enough detail about the tech decisions made to be able to discuss in technical company. take note of interesting algorithms like the min-max color quantization and explain how they work to someone that knows math but has forgotten a lot of it :)</blockquote><p>It built me a document that explained everything in simple language, including a section on color quantization:</p><p><em><strong>Min-Max (Max-Min) Color Quantization</strong><br>To reduce the number of bead colors while preserving image diversity, the app uses a greedy max-min algorithm:</em></p><ol><li><em><strong>Start</strong> with the most common color in the image as the first palette entry.</em></li><li><em><strong>Iteratively add</strong> the color that is farthest (in Euclidean RGB space) from all colors already in the palette.</em></li><li><em><strong>Repeat </strong>until the palette reaches the desired size (e.g., 16 colors) or all unique colors are included.</em></li><li><em><strong>Pad</strong> with white if needed.</em></li></ol><p><em>This ensures the palette covers the full range of colors in the image, not just the most frequent ones, and avoids clustering similar colors.</em></p><h3 id=\"agents-can%E2%80%99t-see\">Agents Can’t See</h3><p>In order for the app to be useful, it needed to generate very precise patterns that fit under the plastic fuse-bead peg boards exactly. If the grid measurements are off by even a millimeter, it can mess up the whole image.<em> </em>I spent a while trying to iterate on the layout with Copilot, but ultimately I had to physically print out the results and hold them up to a peg board to see if it was printing in alignment.</p><p>My first try was way off, even though the measurements were to the correct fuse bead pattern specifications. I needed to iterate, but I realized that printing out a new sheet every time I made a small tweak would have been a huge waste of time and paper, so I had to find another way to test the alignment.</p><p>Luckily, there are tons of free printable fuse bead patterns online, so in order to streamline the process, I downloaded a free PDF and measured all of the allowances in Adobe Acrobat. I fed all of that into Copilot and then took the output and overlayed it on the printable pattern I had downloaded using the excellent Photoshop clone, <a href=\"https://www.photopea.com/?ref=pr.ogra.ms\" rel=\"noreferrer\">Photopea</a>. This gave me a way tighter (and less wasteful) feedback loop and I was able to get a very precise output. After the overlay was exact, I printed out a physical copy to verify it aligned with a real peg board.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://pr.ogra.ms/content/images/2025/06/Greenshot-2025-06-20-17.10.35.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1184\" height=\"414\" srcset=\"https://pr.ogra.ms/content/images/size/w600/2025/06/Greenshot-2025-06-20-17.10.35.png 600w, https://pr.ogra.ms/content/images/size/w1000/2025/06/Greenshot-2025-06-20-17.10.35.png 1000w, https://pr.ogra.ms/content/images/2025/06/Greenshot-2025-06-20-17.10.35.png 1184w\" sizes=\"(min-width: 720px) 720px\"><figcaption><span style=\"white-space: pre-wrap;\">My results overlayed on the original fuse-bead pattern @ 44% opacity</span></figcaption></figure><h3 id=\"sometimes-its-smarter-than-you\">Sometimes it's Smarter Than You</h3><p>It was around this part of the process that I realized that Copilot had done something smart that I hadn't thought of. When I was conceptualizing this app, I assumed it would need a backend API because processing the image would take a long time. But the LLM built all of the processing into the browser, and the UI was actually really snappy. This design simplified a lot of things from my end: I don't have to maintain a compute infrastructure and manage access. This can be hosted directly on a CDN for fast download, and performance is limited only by the user’s own device.</p><p>But the biggest advantage is that because <a href=\"https://melticulous.com/?ref=pr.ogra.ms\" rel=\"noreferrer\">Melticulous</a> runs in the browser, it's completely secure and users don't have to worry about me storing their files, EVER.</p><h3 id=\"the-9090-rule\">The 90/90 Rule</h3><p>All of these early positive results were really encouraging, but the devil is in the details and <a href=\"https://en.wikipedia.org/wiki/Ninety%E2%80%93ninety_rule?ref=pr.ogra.ms\" rel=\"noreferrer\">the 90/90 rule</a> started to set in.</p><blockquote>The first 90 percent of the code accounts for the first 90 percent of the development time. The remaining 10 percent of the code accounts for the other 90 percent of the development time.</blockquote><p>I'm not sure that I can fully pin this on Copilot, as this rule has been around for a long time, but there was a fair amount of whack-a-mole at this stage. I would try to add some UI Calls-to-Action and the grid would be misaligned. Or, I would try to change the wording of something and the buttons would look weird.</p><h3 id=\"use-git-and-commit-often\">Use git and Commit Often</h3><p>I have long had a policy of not writing a stitch of code on any project without doing <em>git init</em> first. It's an excellent habit, and it saved me more than a few times while building this project.</p><p>I was at the point where the app was looking really polished and I decided I needed to add an about page. I had Copilot generate the page and was making some tweaks to the wording when Copilot went rogue and replaced the entire app with a large spinning logo. I loaded up the page after a \"wording edit\" and there was no app anymore, it had reached into the folder and grabbed an image that I wasn't using for anything and made it huge and rotating.</p><p>Then Copilot acted like everything was fine. I tried to argue a bit, and I even tried stepping backward using the built-in functionality, but the app was destroyed at that point. I reverted to a known good version in git and tried again. Don't even think about vibe coding without git. You need it. I'm serious.</p><h3 id=\"test-whats-important-to-you\">Test What's Important to You</h3><p>By the same token, make sure to add unit tests for all of the core functionality that's important to you. To me, the cell alignment of the printed pattern was the most important immutable aspect of this application. So I had Copilot generate a unit test and tested the unit test by purposely screwing up the alignment, forcing the test to fail. </p><p>Unit tests alone aren't enough unless you run them regularly. I asked Copilot to add a step in the <a href=\"https://about.gitlab.com/?ref=pr.ogra.ms\" rel=\"noreferrer\">GitLab</a> Pipeline to run my unit tests before any merge to main.</p><h3 id=\"sometimes-its-just-not-the-agent%E2%80%99s-day\">Sometimes, It's Just Not The Agent’s Day</h3><p>The last bit of caution I'd like to leave people with is that sometimes Copilot, like any developer, gets stuck trying to solve a problem a certain way. You need to be on top of this and realize when it's stuck in a loop trying to do something that will never work. In this situation, you have two options, which you can employ separately or together:</p><ol><li>Start the context over: ask Copilot to summarize the conversation and the work that it's done and store it to a file. Then erase your history and re-describe the problem. Sometimes restating the problem a different way to a brand new instance is enough to nudge Copilot in the right direction.</li><li>Switch models: This may not be a popular opinion, but most of the modern models are almost the same in terms of their abilities. Some really thoughtful tasks require a reasoning model, but other than that, they're pretty interchangeable. So interchange them - don't tie yourself to a given model, think of changing models as a way to change perspective.</li></ol><h3 id=\"conclusion\">Conclusion</h3><p>If you're a software developer, you need to be learning these tools. At this point, it's not optional. Agents aren't going to replace human software engineers, but human engineers that aren't using these tools run the risk of being replaced by human engineers that do.</p><p>If you’re into crafting with Perler Beads, don’t forget to take <a href=\"https://melticulous.com/?ref=pr.ogra.ms\" rel=\"noreferrer\">Melticulous</a> for a spin; and if you have any enhancement ideas, <a href=\"mailto:kimmelb+melticulous@gmail.com\" rel=\"noreferrer\">let me know</a>!</p><p></p>",
    "comment_id": "684b23a89d1d6d0001047191",
    "feature_image": "https://pr.ogra.ms/content/images/2025/06/IMG_0392.jpeg",
    "featured": true,
    "visibility": "public",
    "created_at": "2025-06-12T14:59:52.000-04:00",
    "updated_at": "2025-06-23T22:17:51.000-04:00",
    "published_at": "2025-06-23T17:10:00.000-04:00",
    "custom_excerpt": "Using Copilot Agent Mode, I was able to implement an app idea that I’ve been mulling for years. ",
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "custom_template": null,
    "canonical_url": null,
    "url": "https://pr.ogra.ms/i-wrote-my-dream-app-in-4-hours/",
    "excerpt": "Using Copilot Agent Mode, I was able to implement an app idea that I’ve been mulling for years. ",
    "reading_time": 7,
    "access": true,
    "comments": false,
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "email_subject": null,
    "frontmatter": null,
    "feature_image_alt": null,
    "feature_image_caption": "<a href=\"https://melticulous.com\" rel=\"noreferrer\"><span style=\"white-space: pre-wrap;\">Melticulous</span></a><span style=\"white-space: pre-wrap;\">, an app that turns your images into Perler Bead Patterns</span>"
  },
  {
    "id": "66576ed0cad2e0000138bed1",
    "uuid": "31604698-fc99-445c-b6ae-05bf0c376185",
    "title": "The Three Continuums of Better Software Estimation",
    "slug": "tips-for-better-software-estimation",
    "html": "<p>As a software engineer, you're frequently asked to estimate how long a task will take to complete. Estimation can be a tedious process and it's tempting to just throw out a (usually rosy) date. This approach can quickly get you and your team buried, working nights and weekends to heroically meet dates that were unrealistic to begin with. Better estimates are critical to your health and longevity as a software engineer and this framing can help you keep your workload sustainable, avoid burnout, and as a side effect, give your audience better estimates.</p><h2 id=\"define-better\">Define \"Better\"</h2><p>It's easy to define \"better\" here, right? A better estimate is one where the estimated date provided before the work starts matches the real date that the work was delivered. But what if the team works 80 hour weeks to meet their deadlines and needs a week of recovery time after every production release? Or the opposite; what if the team spent 1 month estimating 3 months of work and hit their date exactly? \"Better\" doesn't always mean \"more accurate.\" A good estimate will <strong><em>give the organization the information it needs to coordinate and make decisions most efficiently.</em></strong></p><p>When a product manager asks how long something will take, they're usually trying to answer a specific question, such as: </p><ul><li><em>When can we tell a client this feature will be done?</em></li><li><em>How does this project affect another team that is dependent on this API to release the new version of their product?</em></li><li><em>Where can I put this project on our publicly available roadmap?</em></li><li><em>How close are we to hitting our quarterly targets?</em></li></ul><p>Surprisingly, <strong>the best possible estimate</strong> for each of the above scenarios<strong> can be different, <em>even for the same body of work</em></strong>.</p><p>Estimating work is just like any project. You're used to defining requirements, asking questions, being clear about the definition of done, etc. when you're building things. You should follow the same process when tasked with estimating a body of work. There are a few questions that you can ask to help you figure out your targets for each of the 3 continuums:</p><p><strong>Who is the audience for this estimate? </strong>The estimate may be for internal projections, internal teams, or it may be widely distributed to clients (or all three.) </p><p><strong>What are the consequences of over- or under-estimating this work?</strong> If you overestimate, will you miss out on a valuable contract? If you underestimate, will you end up working overtime to catch up, only to have the project ultimately cancelled? Do other teams depend on the timing of delivery of this work?</p><p><strong>To what level of detail is this work specified?</strong> Are we t-shirt sizing for a long-term project or is there enough information to break the work down into tasks and assign hours to each task?</p><p>Getting answers to these three questions will give you valuable insight into where on the three continuums of <strong>effort, optimism, </strong>and <strong>certainty</strong> this estimate should fall.</p><h2 id=\"effort\">Effort</h2><p>The amount of effort you put into an estimate can increase your accuracy, up to a point. For almost every estimation exercise, however, there is a point of diminishing returns. The two extreme approaches of this continuum are:</p><ol><li>Respond with an estimate as soon as possible (off-the-cuff); this approach can lead to inaccurate estimates.</li><li>Try to get a full and complete understanding of the work, only then providing an estimate; this approach seems \"correct\" at first, but can actually imply false certainty, which is also inaccurate.</li></ol><p>Finding the point of diminishing returns here is key to providing the right estimate.</p><p>If the work has detailed specifications and the estimate is being used directly in a high-profile contract with a client, it makes sense to take more time to analyze all of the requirements.</p><p>If you're setting quarterly targets, and you only have high-level requirements, discussing minutiae is not an efficient use of time. To be clear, the minutiae and requirements will be discussed (during sprint planning, for example,) but answering every question may not be required for high-level estimates.</p><p>Whether you're estimating the work by yourself or with your team, it's important to focus on details <em>only if the outcome of the discussion would affect the estimate</em>. Try not to mix up requirements communication with estimation, especially when you're estimating at a high level. </p><h2 id=\"optimism\">Optimism</h2><p>Between <a href=\"https://www.standishgroup.com/sample_research_files/CHAOSReport2015-Final.pdf?ref=pr.ogra.ms\" rel=\"noreferrer\">20% and 66% of software projects fail</a>, depending on your criteria for failure. At first glance, you might say that as an industry, we are critically failing in our ability to estimate software projects. And you'd be right, but why?</p><p>One factor that contributes to our failure to estimate well is the <em>natural tendency to give optimistic estimates. </em>Pressure from stakeholders, lack of knowledge of the requirements, personal pride, and <strong><em>the inherent uncertainty in trying to predict the future</em></strong>, all contribute to a culture where software engineers are set up to give rosy estimates.</p><p>So that's an easy problem to fix, right? Just pad all estimates by 30% and you should be good. This works and has worked for years in resource-rich environments. However, in an environment where your teams, proposals, and governance are competing for resources with other teams, and those teams are providing optimistic estimates with no padding, you'll be starved for funding.</p><p>This is why it's crucial to understand your audience and the consequences of over or under estimating for the particular body of work that you're estimating. <em>There are situations where it's appropriate to sacrifice accuracy for optimism and your estimate should be optimistic, and there are situations where going over time or budget is unacceptable.</em></p><p>There are two big ways that you can control your level of optimism when providing an estimate: feedback loops and padding</p><h3 id=\"feedback-loops\">Feedback loops</h3><p>Feedback loops just mean that you have some mechanism for checking your previous estimates against reality, with an eye towards increasing accuracy. </p><p>Retrospectives are a great place to have this discussion with the rest of your team. Make sure that there's time to talk through how much was estimated vs. how much was done during your retrospectives so that you can continuously improve your accuracy. </p><p>A small note: many teams have a formalized feedback loop for task- or story-level estimations, but don't actively try to improve their longer-term estimates. Having retrospectives per-release, per-quarter and beyond can help you plan further into the future (to the extent to which that's possible!)</p><h3 id=\"padding\">Padding</h3><p>Padding is an age-old method for ensuring that your projects don't run over-time or over-budget. It used to be conventional wisdom that each level of management would add 20-30% to every estimate before communicating it out. This method works, but it has a few key drawbacks.</p><p>The first is that it's a very imprecise tool. That could be ok in certain situations where you absolutely, positively must deliver on time. It's impreciseness has the side effect that it's one-size fits all and doesn't scale well. The magnitude of padding on a long-term project with a high degree of uncertainty may be totally different than the padding on a small, well-specified project.</p><p>The second drawback is <a href=\"https://en.wikipedia.org/wiki/Parkinson%27s_law?ref=pr.ogra.ms\" rel=\"noreferrer\">Parkinson's law</a>, <em>\"work expands so as to fill the time available for its completion.\"</em> There is some evidence that this law applies to software engineering and sticking with a defined strategy for estimation, rather than adding a flat padding percent can help mitigate Parkinson's law.</p><p>I would recommend that you use padding sparingly, and when you do, use a defined and transparent methodology that ties the magnitude of padding to level of risk.</p><h2 id=\"certainty\">Certainty</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://pr.ogra.ms/content/images/2024/06/Cone_of_Uncertainty.jpg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"960\" height=\"720\" srcset=\"https://pr.ogra.ms/content/images/size/w600/2024/06/Cone_of_Uncertainty.jpg 600w, https://pr.ogra.ms/content/images/2024/06/Cone_of_Uncertainty.jpg 960w\" sizes=\"(min-width: 720px) 720px\"></figure><p>If you haven't already, stop reading this and go read <a href=\"https://www.amazon.com/Software-Estimation-Demystifying-Developer-Practices/dp/0735605351?ref=pr.ogra.ms\" rel=\"noreferrer\">Steve McConnell's Software Estimation: Demystifying the Black Art</a>. At the heart of this book is a diagram called <strong>The Cone of Uncertainty</strong>. The concept is simple: the earlier in the project you're estimating a body of work, the less accurate the estimate will be.</p><p>It's important to note that the uncertainty does not come from the skill or abilities of the people estimating. <strong>There is nothing you can do to remove the uncertainty without spending time. </strong>Whether you spend that time articulating requirements or iterating, even the most accurate possible estimator can't do better than a .25-4x range at the very beginning of a project.</p><p>We have two ways of incorporating uncertainty into our estimates that can be used in concert: We can improve the specifications, and/or accept and communicate the level of uncertainty.</p><h3 id=\"improve-the-specifications\">Improve the Specifications</h3><p>Even at a high level, there should be some definition of done. The key is to have the appropriate definition of done for the specificity of the estimate. For example, if you're estimating building a complex new page, it's not important to have pixel-perfect mockups for a high-level estimation. Make sure that <em>at a minimum, you have answers to any question that would affect the estimate.</em></p><p>Sometimes you can't get answers to every question you have about the requirements. For that situation, you're going to have to make an assumption about the answer. When you make specification assumptions in order to provide an estimate, make sure to <strong><em>clearly document those assumptions.</em></strong></p><p>As for how to decide on which assumption to choose, ask the person writing requirements (Product Manager, SME, Business Liaison, etc.,) to take their best guess. If they won't venture a guess, you can always choose the option that would take the most time. The key is to document that as an assumption.</p><h3 id=\"acceptcommunicate-the-level-of-uncertainty\">Accept/Communicate the Level of Uncertainty</h3><p>There are a few ways to accept and communicate the level of uncertainty in your estimates. You can include a certainty percentage along with a time, or provide a range of dates rather than a hard deadline. I've found that the game of telephone can strip this extra risk information out of your estimates. The person or team to whom you are providing the estimate may intentionally or unintentionally omit the  percentage or choose a date within the range when they are passing on the information to another party.</p><p>Another way to communicate the level of uncertainty is to codify that in your process. Repeated usage of different types of estimates can acclimate the whole organization to your level of uncertainty for different types of estimates. For this, it helps to give names to different uncertainty levels for different types of work and ensure there is a shared understanding of what they mean.</p><p>A popular taxonomy (from most uncertainty to least uncertainty) is <strong>Initiative, Epic, Story, Task</strong>. Some organizations also use <strong>Theme</strong> and <strong>Feature</strong>. For estimation, it's more important that there's a shared understanding of what level of uncertainty each of these maps to than the actual words you use to describe those levels.</p><h2 id=\"the-key-to-better-estimates\">The Key to \"Better\" estimates</h2><p>The key to better estimates is to understand that, just like all software deliverables, the \"why\" matters just as much as the \"what\" does. The task of estimation itself has requirements that you need to understand. When you find out more about what each estimate will be used for, you can tweak the sliders on each of the three continuums of <strong>effort, optimism, and certainty</strong> to provide a customized result that <strong><em>above all, meets the requirements of the estimate itself.</em></strong></p><p></p><h2 id=\"bonus-estimation-advice\">Bonus Estimation Advice</h2><p><em>You </em>may understand the above, and be working toward clarifying a shared understanding within your organization, but not everyone will exactly align on this framework. For that, I have a few helpful tips:</p><p><strong><em>Never provide off-the-cuff estimates</em></strong> If someone tries to pressure you into estimating something over the phone without having any requirements in writing and without giving you time to think, I advise you not to give an estimate if at all possible. Asking for off-the-cuff estimates and pressuring software engineers for a quick answer is a way to codify and enforce unrealistic timelines, leading to burnout. If someone can't wait for you to have an amount of time with the requirements that's appropriate for the level of uncertainty, then they are usually trying to trap you into giving a rosy estimate and reserving the right for future feature creep. Protect your mental and physical health and well-being by having clear boundaries about this.</p><p><strong><em>Only estimate work that you or your team will be doing</em></strong>. Estimates are not transferrable, you can't tell someone how long it will take another person to complete a software development task. If you are a leader or manager, don't estimate tasks that your team will be implementing, bring them into the estimation process. Part of the estimation process is a commitment from the estimator to aim for the date provided (given all assumptions and caveats mentioned above.) This commitment gives the people doing the work accountability and buy-in for the estimate. You can't make that commitment for another person or team.</p><p></p>",
    "comment_id": "66576ed0cad2e0000138bed1",
    "feature_image": "https://pr.ogra.ms/content/images/2024/05/Estimation-Sliders.jpg",
    "featured": false,
    "visibility": "public",
    "created_at": "2024-05-29T14:07:12.000-04:00",
    "updated_at": "2024-06-02T18:18:21.000-04:00",
    "published_at": "2024-06-02T18:18:21.000-04:00",
    "custom_excerpt": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "custom_template": null,
    "canonical_url": null,
    "url": "https://pr.ogra.ms/tips-for-better-software-estimation/",
    "excerpt": "As a software engineer, you're frequently asked to estimate how long a task will take to complete. Estimation can be a tedious process and it's tempting to just throw out a (usually rosy) date. This approach can quickly get you and your team buried, working nights and weekends to heroically meet dates that were unrealistic to begin with. Better estimates are critical to your health and longevity as a software engineer and this framing can help you keep your workload sustainable, avoid burnout, a",
    "reading_time": 8,
    "access": true,
    "comments": false,
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "email_subject": null,
    "frontmatter": null,
    "feature_image_alt": "Three futuristic-looking slider bars stacked on top of each other with the labels, in order: EFFORT, OPTIMISM, and CERTAINTY",
    "feature_image_caption": null
  },
  {
    "id": "660050d824eea30001bc6b0e",
    "uuid": "f330c210-0f94-40e4-aed1-cc1dec20fd44",
    "title": "Writing Job Descriptions to Attract Talented Software Engineers",
    "slug": "writing-good-job-descriptions",
    "html": "<p>Whether the current talent pool of software engineers is large or small; as a hiring manager, you have essentially the same problem: attracting and identifying talented individuals that will be able to add value to your team.</p><p><strong>In a saturated job market</strong>, you'll get tons of CVs, but you'll need to be incredibly discerning to find folks that will meet your teams' needs.</p><p><strong>In a market where the talent pool is limited</strong>, you will really need to sell yourself, your team, and your organization to get great engineers to apply to your positions in the first place.</p><p>In either case, your candidates' first impression of you and your team is in the job posting, and many hiring managers don't take the time to thoughtfully consider what their job description communicates to potential candidates.</p><p>Here is some practical advice for making a great first impression, and attracting great talent (identifying and hiring great talent during the interview process is a topic for another time.) </p><h2 id=\"include-the-salary-range-in-the-job-posting\">Include the Salary Range in the Job Posting</h2><p>This should be a no-brainer at this point, but the absolute worst managers to work for are ones that waste your time. If you don't include the salary range in your job description, it's either because you pay below market value, or you don't have transparent pay scales and don't want your current employees to know how much you're willing to pay the new team member. Either way, it's a huge red flag and most great developers will scroll right past.</p><p>Some localities <a href=\"https://www.postercompliance.com/blog/wage-transparency-laws-2023/?ref=pr.ogra.ms\" rel=\"noreferrer\">require</a> a salary range to be posted for companies that have more than X number of employees or meet other criteria. Many hiring managers use this as an opportunity to post a <a href=\"https://www.forbes.com/sites/jackkelly/2023/06/06/companies-posting-wide-salary-ranges-on-job-advertisements-are-making-a-mockery-of-pay-transparency-laws/?sh=3489989e4865&ref=pr.ogra.ms\" rel=\"noreferrer\">range that's so wide</a> that it's meaningless.</p><p>Always provide a meaningful range in your job postings. Otherwise, you’re clogging your hiring pipeline and wasting your own time.</p><h2 id=\"clearly-state-whether-the-position-is-remote\">Clearly State Whether the Position is Remote</h2><p>Be very clear <strong>and truthful </strong>in your job description about whether the position is remote, hybrid, or in-office fulltime. Include any information about travel for joint meetings, such as quarterly retreats or in-person client meetings. Like salary, you and the candidate should be pre-aligned on this before you even have a phone screen.</p><p>If you're hiring for a remote-capable job (which applies to all software engineering jobs,) and you're forcing people to come to an office, please reconsider how committed you are to hiring great talent. Not everyone likes working remotely, but how many great engineers that prefer in-office live within an hour's commute to your office?</p><p>As a good hiring manager, also make sure that if the job description was written as remote, that it is codified in the employment contract. This will add a small layer of protection against future return-to-office initiatives (but if leadership really wants folks in the office, <a href=\"https://www.bloomberg.com/news/articles/2022-11-10/musk-s-first-email-to-twitter-staff-ends-remote-work?ref=pr.ogra.ms\" rel=\"noreferrer\">there's not much you can do</a>.)</p><h2 id=\"be-transparent-about-visa-sponsorship\">Be Transparent About Visa Sponsorship</h2><p>These first three tips can be summarized as <strong><em>don't waste people's time</em></strong>, but this is an order of magnitude more important when talking about visa sponsorship. If you misrepresent your company's visa sponsorship process, and the candidate only finds out the truth after being hired, you're risking their ability to remain in the country. Familiarize yourself with the process ahead of time and be clear about what your company is open to in the posting.</p><h2 id=\"be-specific-about-requirements\">Be Specific About Requirements</h2><p>If you have interview questions about a specific technology, or really need someone with a lot of expertise with a niche library, list that in the description. By the same token, take a hard look at your list of requirements and decide if each is really necessary or just nice to have.</p><p>The idea is to be up-front about how you will be evaluating candidates without unnecessarily limiting your audience. With that in mind;</p><h2 id=\"consider-equivalent-experience\">Consider Equivalent Experience</h2><p>Many hiring managers include a college degree as a requirement, even for mid or senior level engineering positions. If someone has had 5 years of real-world experience, does it matter if they originally learned software development from a JavaScript from a boot camp? A fantastic self-starter can be a massive asset to your team, excluding them from the get-go really limits your choices. </p><p>In the same vein, is a particular technology really required, or are there comparable skills that would expand your candidate pool? For example, someone that has 3 years of experience in Angular could probably pick up React pretty quickly.</p><p>In fact, years of experience in X technology is a pretty useless metric for competence in that technology. What matters is level of proficiency, which people tend to be pretty honest about. You can evaluate that proficiency in the interview. Instead of years of experience in particular technologies, use language like “working knowledge,” “proficient in,” or “expert in.” Never ever use words like guru, rock star, or ninja (see <strong>Use Inclusive Language</strong> below.)</p><h2 id=\"be-truthful-about-reponsibilities\">Be Truthful About Reponsibilities</h2><p>If you’re hiring a hands-on manager or lead, include a breakdown of how much time you're expecting the person to be coding vs. leadership and mentoring. If you’re working with a legacy codebase, include what percentage of day-to-day work is bug fixes vs. new features.</p><p>The most important rule of writing a good responsibilities section is to be as honest as possible. hiring someone that expects to be writing mostly features, but ends up working primarily on bug fixes doesn’t help you or the candidate. They’ll leave the company for greener pastures and you’ll just be redoing this process again in three months. Or worse, they’ll stay and hate their job. </p><h2 id=\"use-inclusive-language\">Use Inclusive Language</h2><p>Actively combatting systemic discrimination is a moral imperative. As a hiring manager and manager in general, recognize that you are participating in a system designed to oppress people based on race, gender, sexuality and physical ability. treating everyone fairly and equitably is the <em>bare minimum</em>. You should strive to find ways to actively reach out to systemically marginalized folks.</p><p>This philosophy aligns very well with writing an effective job posting. Using language that demonstrates dedication to being welcoming to all will give you more well qualified folks to choose from.</p><p>This shouldn’t only be limited to boilerplate inclusivity text at the end, though crafting a good version of that can be helpful. </p><p>To start, don’t use gendered pronouns. Run the entire job description through a gender bias decoder, such as <a href=\"http://gender-decoder.katmatfield.com/?ref=pr.ogra.ms\">http://gender-decoder.katmatfield.com</a>.  Use an LLM to try to find bias in your job description.</p><p>Don’t use words like guru, ninja, master, samurai or rock-star. Not only do these words carry cultural and gender significance that you’re probably not trying to invoke, but they also suggest an unrealistic standard that will discourage qualified candidates and they imply a terrible work-life balance. Assuming that supernatural software engineering powers don’t exist, the only way a candidate could live up to a superfluous title is by overworking. </p><p>These methods are not perfect, so continue to do your homework by reading scholarship on anti-racism, feminism, and systemic oppression. </p><h2 id=\"in-summary\">In Summary</h2><p>As a hiring manager, your job posting is the first impression candidates have of you, your team, and your company. the keys are: don’t wast anyone’s time, be specific about requirements, and accurately communicate the working environment. Also remember that it’s your responsibility to live up to your good first impression.</p>",
    "comment_id": "660050d824eea30001bc6b0e",
    "feature_image": null,
    "featured": false,
    "visibility": "public",
    "created_at": "2024-03-24T12:12:08.000-04:00",
    "updated_at": "2024-05-12T11:01:38.000-04:00",
    "published_at": "2024-05-12T11:01:38.000-04:00",
    "custom_excerpt": null,
    "codeinjection_head": null,
    "codeinjection_foot": null,
    "custom_template": null,
    "canonical_url": null,
    "url": "https://pr.ogra.ms/writing-good-job-descriptions/",
    "excerpt": "Whether the current talent pool of software engineers is large or small; as a hiring manager, you have essentially the same problem: attracting and identifying talented individuals that will be able to add value to your team.\n\nIn a saturated job market, you'll get tons of CVs, but you'll need to be incredibly discerning to find folks that will meet your teams' needs.\n\nIn a market where the talent pool is limited, you will really need to sell yourself, your team, and your organization to get grea",
    "reading_time": 5,
    "access": true,
    "comments": false,
    "og_image": null,
    "og_title": null,
    "og_description": null,
    "twitter_image": null,
    "twitter_title": null,
    "twitter_description": null,
    "meta_title": null,
    "meta_description": null,
    "email_subject": null,
    "frontmatter": null,
    "feature_image_alt": null,
    "feature_image_caption": null
  }
]